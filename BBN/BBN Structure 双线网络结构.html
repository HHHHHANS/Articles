<html>
<head>
  <title>Evernote Export</title>
  <basefont face="微软雅黑" size="2" />
  <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
  <meta name="exporter-version" content="YXBJ Windows/602051 (zh-CN, DDL); Windows/6.1.1 (Win64); EDAMVersion=V2;"/>
  <meta name="content-class" content="yinxiang.markdown"/>
  <style>
    body, td {
      font-family: 微软雅黑;
      font-size: 10pt;
    }
  </style>
</head>
<body>
<a name="719"/>
<h1>BBN Structure 双线网络结构</h1>

<div><span><div style="font-size: 14px; margin: 0; padding: 0; width: 100%;"><h1 style="line-height: 160%; box-sizing: content-box; font-weight: 700; font-size: 41px; border-bottom: 3px double #999; color: #000; margin-top: 14px;">BBN Structure 双线网络结构</h1>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;">论文标题 <a style="line-height: 160%; box-sizing: content-box; text-decoration: underline; color: #5286bc;"> Bilateral-Branch Network with Cumulative Learning for Long-Tailed Visual Recognition</a></p>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;"><a href="https://github.com/Megvii-Nanjing/BBN" style="line-height: 160%; box-sizing: content-box; text-decoration: underline; color: #5286bc;">Github源码</a><br/>
<img src="BBN Structure 双线网络结构_files/Image.png" type="image/png" data-filename="Image.png"/><br/>
<strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">两条线各自对不同采样方式的样本进行特征学习和分类学习，最后汇总到累积学习结构中</strong></p>
<blockquote style="line-height: 160%; box-sizing: content-box; margin: 15px 0; border-left: 4px solid #ddd; padding: 0 15px; color: #777;">
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333; margin-top: 0; margin-bottom: 0;"> <em style="line-height: 160%; box-sizing: content-box; font-style: italic;">Concretely, we design two branches for representation learning and classifier learning, termed “conventional learning branch” and “re-balancing branch”,respectively. Both branches use the same residual network structure and share all the weights except for the last residual block.<br/>
 Furthermore, we also design a specific cumulative learning strategy for shifting the learning “attention” between two branches in the training phase.</em></p>
</blockquote>
<h2 style="line-height: 160%; box-sizing: content-box; font-weight: 700; font-size: 34px; border-bottom: 1px solid #dbdbdb; color: #333;">双边网络层</h2>
<h3 style="line-height: 160%; box-sizing: content-box; font-weight: 700; font-size: 27px; color: #333;">数据采样-Data samplers</h3>
<ul style="line-height: 160%; box-sizing: content-box; display: block; list-style-type: disc; padding-left: 30px; margin: 6px 0 10px; color: #333;">
<li style="line-height: 160%; box-sizing: content-box; position: relative;">
<h4 style="line-height: 160%; box-sizing: content-box; font-size: 20px; color: #333;">conventional learning branch</h4>
</li>
</ul>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;">对所有样本数据进行均匀采样，得出一个样本</p>
<ul style="line-height: 160%; box-sizing: content-box; display: block; list-style-type: disc; padding-left: 30px; margin: 6px 0 10px; color: #333;">
<li style="line-height: 160%; box-sizing: content-box; position: relative;">
<h4 style="line-height: 160%; box-sizing: content-box; font-size: 20px; color: #333;">re-balancing branch</h4>
</li>
</ul>
<ol style="line-height: 160%; box-sizing: content-box; display: block; padding-left: 30px; margin: 6px 0 10px; color: #333; list-style-type: decimal;">
<li style="line-height: 160%; box-sizing: content-box;">计算各类别的数据采样概率</li>
<li style="line-height: 160%; box-sizing: content-box;">通过采样概率，随机选定某类样本</li>
<li style="line-height: 160%; box-sizing: content-box;">通过选定的某类（标签），均匀采样出一个样本</li>
</ol>
<blockquote style="line-height: 160%; box-sizing: content-box; margin: 15px 0; border-left: 4px solid #ddd; padding: 0 15px; color: #777;">
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333; margin-top: 0; margin-bottom: 0;"><img src="BBN Structure 双线网络结构_files/Image [1].png" type="image/png" data-filename="Image.png"/><br/>
<img src="BBN Structure 双线网络结构_files/Image [2].png" type="image/png" data-filename="Image.png"/><br/>
Ni为某类（标签）的样本数<br/>
Nmax为规模最大的类（标签）的样本数</p>
</blockquote>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;">两条线每次进入的x为一个常规采样和一个re-sampling的一个样本，<br/>
多次反复该步骤形成了mini-batch。</p>
<h3 style="line-height: 160%; box-sizing: content-box; font-weight: 700; font-size: 27px; color: #333;">权重共享-Weight sharing</h3>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;">双线的网络结构除了最后一个residual block，其余都是使用相同的网络结构和权重（例如ResNet-32和ResNet-50）</p>
<blockquote style="line-height: 160%; box-sizing: content-box; margin: 15px 0; border-left: 4px solid #ddd; padding: 0 15px; color: #777;">
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333; margin-top: 0; margin-bottom: 0;">  On the one hand, the well-learned representation by the conventional learning branch can benefit the learning of the re-balancing branch. On the other hand, sharing weights will largely reduce computational complexity in the inference phase.</p>
</blockquote>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;">分析：先使用conventional learning对常规采样样本进行前向传播，得出常规特征向量fc，使用相同的网络对re-balancing learning的re-sampling样本进行前向传播。</p>
<h3 style="line-height: 160%; box-sizing: content-box; font-weight: 700; font-size: 27px; color: #333;">GAP</h3>
<blockquote style="line-height: 160%; box-sizing: content-box; margin: 15px 0; border-left: 4px solid #ddd; padding: 0 15px; color: #777;">
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333; margin-top: 0; margin-bottom: 0;"><em style="line-height: 160%; box-sizing: content-box; font-style: italic;">Global average pooling</em></p>
</blockquote>
<h2 style="line-height: 160%; box-sizing: content-box; font-weight: 700; font-size: 34px; border-bottom: 1px solid #dbdbdb; color: #333;">积学习层-Cumulative learning</h2>
<blockquote style="line-height: 160%; box-sizing: content-box; margin: 15px 0; border-left: 4px solid #ddd; padding: 0 15px; color: #777;">
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333; margin-top: 0; margin-bottom: 0;"><img src="BBN Structure 双线网络结构_files/Image [3].png" type="image/png" data-filename="Image.png"/></p>
</blockquote>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;">  在积学习层，设置一个会动态调整大小的α参数，表示不同epoch时候对两边的特征向量分配的权重大小，即分配不同的注意力。<strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">因为α是递减的，因此模型的整体训练重心会从head-info转向tail-info。</strong></p>
<h2 style="line-height: 160%; box-sizing: content-box; font-weight: 700; font-size: 34px; border-bottom: 1px solid #dbdbdb; color: #333;">推理阶段</h2>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;">训练完成后的在推理阶段，<strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">α会被设置成0.5</strong>，表示在此阶段，常规线与Re线的特征矩阵应该分配相同的注意力，得到两个预测logits，最后通过矩阵元素逐个相加得到分类预测结果。</p>
</div><center style="display:none !important;visibility:collapse !important;height:0 !important;white-space:nowrap;width:100%;overflow:hidden">%23%20BBN%20Structure%20%E5%8F%8C%E7%BA%BF%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%0A%E8%AE%BA%E6%96%87%E6%A0%87%E9%A2%98%20%5B%C2%A0Bilateral-Branch%20Network%20with%20Cumulative%20Learning%20for%20Long-Tailed%20Visual%20Recognition%5D()%0A%5BGithub%E6%BA%90%E7%A0%81%5D(%C2%A0https%3A%2F%2Fgithub.com%2FMegvii-Nanjing%2FBBN)%0A!%5B3d300fc0ef4341205bef20a9d030e8f3.png%5D(en-resource%3A%2F%2Fdatabase%2F725%3A1)%0A__%E4%B8%A4%E6%9D%A1%E7%BA%BF%E5%90%84%E8%87%AA%E5%AF%B9%E4%B8%8D%E5%90%8C%E9%87%87%E6%A0%B7%E6%96%B9%E5%BC%8F%E7%9A%84%E6%A0%B7%E6%9C%AC%E8%BF%9B%E8%A1%8C%E7%89%B9%E5%BE%81%E5%AD%A6%E4%B9%A0%E5%92%8C%E5%88%86%E7%B1%BB%E5%AD%A6%E4%B9%A0%EF%BC%8C%E6%9C%80%E5%90%8E%E6%B1%87%E6%80%BB%E5%88%B0%E7%B4%AF%E7%A7%AF%E5%AD%A6%E4%B9%A0%E7%BB%93%E6%9E%84%E4%B8%AD__%0A%3E%26emsp%3B_Concretely%2C%20we%20design%20two%20branches%20for%20representation%20learning%20and%20classifier%20learning%2C%20termed%20%E2%80%9Cconventional%20learning%20branch%E2%80%9D%20and%20%E2%80%9Cre-balancing%20branch%E2%80%9D%2Crespectively.%20Both%20branches%20use%20the%20same%20residual%20network%20structure%20and%20share%20all%20the%20weights%20except%20for%20the%20last%20residual%20block.%20%0A%3E%26emsp%3BFurthermore%2C%20we%20also%20design%20a%20specific%20cumulative%20learning%20strategy%20for%20shifting%20the%20learning%20%E2%80%9Cattention%E2%80%9D%20between%20two%20branches%20in%20the%20training%20phase._%0A%0A%0A%0A%0A%23%23%20%E5%8F%8C%E8%BE%B9%E7%BD%91%E7%BB%9C%E5%B1%82%0A%23%23%23%20%E6%95%B0%E6%8D%AE%E9%87%87%E6%A0%B7-Data%20samplers%0A%2B%20%23%23%23%23%20conventional%20learning%20branch%0A%E5%AF%B9%E6%89%80%E6%9C%89%E6%A0%B7%E6%9C%AC%E6%95%B0%E6%8D%AE%E8%BF%9B%E8%A1%8C%E5%9D%87%E5%8C%80%E9%87%87%E6%A0%B7%EF%BC%8C%E5%BE%97%E5%87%BA%E4%B8%80%E4%B8%AA%E6%A0%B7%E6%9C%AC%0A%2B%20%23%23%23%23%20re-balancing%20branch%0A1.%20%E8%AE%A1%E7%AE%97%E5%90%84%E7%B1%BB%E5%88%AB%E7%9A%84%E6%95%B0%E6%8D%AE%E9%87%87%E6%A0%B7%E6%A6%82%E7%8E%87%0A2.%20%E9%80%9A%E8%BF%87%E9%87%87%E6%A0%B7%E6%A6%82%E7%8E%87%EF%BC%8C%E9%9A%8F%E6%9C%BA%E9%80%89%E5%AE%9A%E6%9F%90%E7%B1%BB%E6%A0%B7%E6%9C%AC%0A3.%20%E9%80%9A%E8%BF%87%E9%80%89%E5%AE%9A%E7%9A%84%E6%9F%90%E7%B1%BB%EF%BC%88%E6%A0%87%E7%AD%BE%EF%BC%89%EF%BC%8C%E5%9D%87%E5%8C%80%E9%87%87%E6%A0%B7%E5%87%BA%E4%B8%80%E4%B8%AA%E6%A0%B7%E6%9C%AC%0A%0A%3E%20!%5B04cf2a93fa6d85d97b36c88e466b7ece.png%5D(en-resource%3A%2F%2Fdatabase%2F721%3A1)%0A%3E%20!%5B3f4983b8e7d8954fed0a825b44e1e141.png%5D(en-resource%3A%2F%2Fdatabase%2F723%3A1)%0A%3ENi%E4%B8%BA%E6%9F%90%E7%B1%BB%EF%BC%88%E6%A0%87%E7%AD%BE%EF%BC%89%E7%9A%84%E6%A0%B7%E6%9C%AC%E6%95%B0%0A%3ENmax%E4%B8%BA%E8%A7%84%E6%A8%A1%E6%9C%80%E5%A4%A7%E7%9A%84%E7%B1%BB%EF%BC%88%E6%A0%87%E7%AD%BE%EF%BC%89%E7%9A%84%E6%A0%B7%E6%9C%AC%E6%95%B0%0A%0A%E4%B8%A4%E6%9D%A1%E7%BA%BF%E6%AF%8F%E6%AC%A1%E8%BF%9B%E5%85%A5%E7%9A%84x%E4%B8%BA%E4%B8%80%E4%B8%AA%E5%B8%B8%E8%A7%84%E9%87%87%E6%A0%B7%E5%92%8C%E4%B8%80%E4%B8%AAre-sampling%E7%9A%84%E4%B8%80%E4%B8%AA%E6%A0%B7%E6%9C%AC%EF%BC%8C%0A%E5%A4%9A%E6%AC%A1%E5%8F%8D%E5%A4%8D%E8%AF%A5%E6%AD%A5%E9%AA%A4%E5%BD%A2%E6%88%90%E4%BA%86mini-batch%E3%80%82%0A%0A%23%23%23%20%E6%9D%83%E9%87%8D%E5%85%B1%E4%BA%AB-Weight%20sharing%0A%E5%8F%8C%E7%BA%BF%E7%9A%84%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E9%99%A4%E4%BA%86%E6%9C%80%E5%90%8E%E4%B8%80%E4%B8%AAresidual%20block%EF%BC%8C%E5%85%B6%E4%BD%99%E9%83%BD%E6%98%AF%E4%BD%BF%E7%94%A8%E7%9B%B8%E5%90%8C%E7%9A%84%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E5%92%8C%E6%9D%83%E9%87%8D%EF%BC%88%E4%BE%8B%E5%A6%82ResNet-32%E5%92%8CResNet-50%EF%BC%89%0A%3E%26emsp%3B%20On%20the%20one%20hand%2C%20the%20well-learned%20representation%20by%20the%20conventional%20learning%20branch%20can%20benefit%20the%20learning%20of%20the%20re-balancing%20branch.%20On%20the%20other%20hand%2C%20sharing%20weights%20will%20largely%20reduce%20computational%20complexity%20in%20the%20inference%20phase.%0A%0A%E5%88%86%E6%9E%90%EF%BC%9A%E5%85%88%E4%BD%BF%E7%94%A8conventional%20learning%E5%AF%B9%E5%B8%B8%E8%A7%84%E9%87%87%E6%A0%B7%E6%A0%B7%E6%9C%AC%E8%BF%9B%E8%A1%8C%E5%89%8D%E5%90%91%E4%BC%A0%E6%92%AD%EF%BC%8C%E5%BE%97%E5%87%BA%E5%B8%B8%E8%A7%84%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8Ffc%EF%BC%8C%E4%BD%BF%E7%94%A8%E7%9B%B8%E5%90%8C%E7%9A%84%E7%BD%91%E7%BB%9C%E5%AF%B9re-balancing%20learning%E7%9A%84re-sampling%E6%A0%B7%E6%9C%AC%E8%BF%9B%E8%A1%8C%E5%89%8D%E5%90%91%E4%BC%A0%E6%92%AD%E3%80%82%0A%23%23%23%20GAP%0A%3E%20*Global%20average%20pooling*%0A%0A%23%23%20%E7%A7%AF%E5%AD%A6%E4%B9%A0%E5%B1%82-Cumulative%20learning%0A%0A%3E!%5Be3f07a635790bc28b0ffc85b45e7d319.png%5D(en-resource%3A%2F%2Fdatabase%2F727%3A0)%0A%0A%26emsp%3B%20%E5%9C%A8%E7%A7%AF%E5%AD%A6%E4%B9%A0%E5%B1%82%EF%BC%8C%E8%AE%BE%E7%BD%AE%E4%B8%80%E4%B8%AA%E4%BC%9A%E5%8A%A8%E6%80%81%E8%B0%83%E6%95%B4%E5%A4%A7%E5%B0%8F%E7%9A%84%CE%B1%E5%8F%82%E6%95%B0%EF%BC%8C%E8%A1%A8%E7%A4%BA%E4%B8%8D%E5%90%8Cepoch%E6%97%B6%E5%80%99%E5%AF%B9%E4%B8%A4%E8%BE%B9%E7%9A%84%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F%E5%88%86%E9%85%8D%E7%9A%84%E6%9D%83%E9%87%8D%E5%A4%A7%E5%B0%8F%EF%BC%8C%E5%8D%B3%E5%88%86%E9%85%8D%E4%B8%8D%E5%90%8C%E7%9A%84%E6%B3%A8%E6%84%8F%E5%8A%9B%E3%80%82**%E5%9B%A0%E4%B8%BA%CE%B1%E6%98%AF%E9%80%92%E5%87%8F%E7%9A%84%EF%BC%8C%E5%9B%A0%E6%AD%A4%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%95%B4%E4%BD%93%E8%AE%AD%E7%BB%83%E9%87%8D%E5%BF%83%E4%BC%9A%E4%BB%8Ehead-info%E8%BD%AC%E5%90%91tail-info%E3%80%82**%0A%0A%23%23%20%E6%8E%A8%E7%90%86%E9%98%B6%E6%AE%B5%0A%20%20%E8%AE%AD%E7%BB%83%E5%AE%8C%E6%88%90%E5%90%8E%E7%9A%84%E5%9C%A8%E6%8E%A8%E7%90%86%E9%98%B6%E6%AE%B5%EF%BC%8C**%CE%B1%E4%BC%9A%E8%A2%AB%E8%AE%BE%E7%BD%AE%E6%88%900.5**%EF%BC%8C%E8%A1%A8%E7%A4%BA%E5%9C%A8%E6%AD%A4%E9%98%B6%E6%AE%B5%EF%BC%8C%E5%B8%B8%E8%A7%84%E7%BA%BF%E4%B8%8ERe%E7%BA%BF%E7%9A%84%E7%89%B9%E5%BE%81%E7%9F%A9%E9%98%B5%E5%BA%94%E8%AF%A5%E5%88%86%E9%85%8D%E7%9B%B8%E5%90%8C%E7%9A%84%E6%B3%A8%E6%84%8F%E5%8A%9B%EF%BC%8C%E5%BE%97%E5%88%B0%E4%B8%A4%E4%B8%AA%E9%A2%84%E6%B5%8Blogits%EF%BC%8C%E6%9C%80%E5%90%8E%E9%80%9A%E8%BF%87%E7%9F%A9%E9%98%B5%E5%85%83%E7%B4%A0%E9%80%90%E4%B8%AA%E7%9B%B8%E5%8A%A0%E5%BE%97%E5%88%B0%E5%88%86%E7%B1%BB%E9%A2%84%E6%B5%8B%E7%BB%93%E6%9E%9C%E3%80%82</center></span>
</div></body></html> 